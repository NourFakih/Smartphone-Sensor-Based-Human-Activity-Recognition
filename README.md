# Smartphone-Sensor-Based-Human-Activity-Recognition

## Human Activity Recognition with Feature Engineering and Deep Fusion

## üìå Motivation

Human Activity Recognition (HAR) using wearable sensors is a critical component in various applications, from health monitoring to smart environments. While deep learning has gained attention for its representation power, classical machine learning pipelines‚Äîespecially when powered by strong signal processing and feature engineering‚Äîcan still outperform deep models on moderately sized datasets. This project investigates the performance trade-off between handcrafted feature pipelines and deep neural models using the UCI HAR dataset.

---

## üóÇÔ∏è Repository Contents

This repository includes three Jupyter notebooks:

1. üìò‚ÄØ**FeatureEngineering+model.ipynb**
   This notebook implements a complete feature engineering pipeline to reduce the original 561 features to a compact set of 100 features. The following 10 pipelines were trained and evaluated on these features:

   * ‚úÖ‚ÄØDecision Tree ‚Äì 100.0%
   * ‚úÖ‚ÄØXGBoost (Full) ‚Äì 100.0%
   * ‚úÖ‚ÄØLinear SVC on PCA Features ‚Äì 93.8%
   * ‚úÖ‚ÄØLinear SVC on Time-Domain Only ‚Äì 93.6%
   * ‚úÖ‚ÄØLinear SVC on Frequency-Domain Only ‚Äì 83.4%
   * ‚úÖ‚ÄØLSTM Classifier ‚Äì 99.86%
   * ‚úÖ‚ÄØPhysics-Informed LSTM (PINN) ‚Äì 84.76%
   * ‚úÖ‚ÄØTransformer Encoder ‚Äì 93.72%
   * ‚úÖ‚ÄØAutoregressive (AR) + SVM ‚Äì 93.0%
   * ‚úÖ‚ÄØVariational Autoencoder (VAE) + SVM ‚Äì 66.0%

   Feature engineering steps include duplicate feature removal, variance thresholding, multicollinearity filtering using Pearson correlation, and selection of the top 100 features via ANOVA F-statistics.

2. üìò‚ÄØ**NOFeatureEngineering+model.ipynb**
   This notebook replicates the model training process using the complete unfiltered set of 561 features. It enables side-by-side comparisons to evaluate the benefit of feature selection and dimensionality reduction. Here‚Äôs a summary of test performance for the same 10 models:

   * Decision Tree ‚Äì 100.0%
   * XGBoost ‚Äì 100.0%
   * Linear SVC on PCA Features ‚Äì 96.2%
   * Linear SVC on Time-Domain Only ‚Äì 96.1%
   * Linear SVC on Frequency-Domain Only ‚Äì 93.8%
   * LSTM ‚Äì 99.23%
   * PINN ‚Äì 88.12%
   * Transformer ‚Äì 93.72%
   * AR + SVM ‚Äì 95.0%
   * VAE + SVM ‚Äì 78.0%

   This notebook reveals that while raw features can support strong classifiers, reduced features yield models that are lighter and potentially more robust to noise or overfitting.

3. üìò‚ÄØ**FFt+models\_(3).ipynb**
   This notebook works directly with the raw 3D accelerometer and gyroscope signals, applying FFT-based feature extraction. It investigates MLP-based models on these frequency-domain representations. While the results (\~95% with MLP) are promising, they were not included in the formal paper to avoid overcrowding the comparison. Nevertheless, they reinforce the viability of using raw-to-FFT pipelines for HAR tasks.

---
> Several modeling ideas were adapted or extended from public Kaggle notebooks that inspired our pipelines \[1]\[2]\[3]\[4]. Their thoughtful analyses, modeling strategies, and clean implementation were instrumental in shaping the final structure of our experiments.

## üìù Project Summary

We benchmarked classical and deep models using both engineered and unfiltered feature sets. Our experiments show that:

* Handcrafted features with XGBoost achieved the highest overall test accuracy (100%) and macro-F1 score (0.992).
* LSTM models benefited from expert features, scoring up to 99.86% with engineering vs. 99.23% without.
* Models like Transformer and PINN performed decently (84‚Äì94%) but were sensitive to input dimensionality and training volume.
* VAE-based pipelines lagged significantly, suggesting that reconstruction-driven representations may not align well with HAR classification goals.
* Frequency-only models underperformed compared to time-only and full models, but retained moderate predictive power (\~83‚Äì94%).

These findings align with the broader literature: on small-to-medium HAR datasets, classical pipelines with well-chosen features remain extremely competitive‚Äîeven compared to modern neural models.

---

## üìö Citation

If you use this dataset or replicate our pipelines, please cite:

```bibtex
@misc{reyes2013har,
  author       = {Reyes-Ortiz, Jorge and Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier},
  title        = {Human Activity Recognition Using Smartphones [Dataset]},
  year         = {2013},
  publisher    = {UCI Machine Learning Repository},
  howpublished = {\url{https://doi.org/10.24432/C54S4K}},
  note         = {Accessed: 2025-05-04}
}
```


## üìö References

\[1] Morris B. (n.d.). What does your smartphone know about you? Kaggle. [https://www.kaggle.com/code/morrisb/what-does-your-smartphone-know-about-you/notebook](https://www.kaggle.com/code/morrisb/what-does-your-smartphone-know-about-you/notebook)
\[2] Chunduru P. (n.d.). SVM for Multiclass Classification. Kaggle. [https://www.kaggle.com/code/pranathichunduru/svm-for-multiclass-classification](https://www.kaggle.com/code/pranathichunduru/svm-for-multiclass-classification)
\[3] Mohamed E. (n.d.). Human Activity Recognition: Scientific Perspective. Kaggle. [https://www.kaggle.com/code/essammohamed4320/human-activity-recognition-scientific-prespective#Time-Domain](https://www.kaggle.com/code/essammohamed4320/human-activity-recognition-scientific-prespective#Time-Domain)
\[4] Meesala P. (n.d.). Human Activity Recognition - LSTM. Kaggle. [https://www.kaggle.com/code/prasadmeesala/human-activity-recognition-lstm](https://www.kaggle.com/code/prasadmeesala/human-activity-recognition-lstm)


---



